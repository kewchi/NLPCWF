# -*- coding: utf-8 -*-
"""NLPCWF_app.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jEhqaVaEV2fv3Lg06URTjWMQq-IpAg9y
"""

# Commented out IPython magic to ensure Python compatibility.
from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline
import streamlit as st

# Create the Streamlit app and set the title
st.title("Streamlit Question Answering App ðŸ¦œ ðŸ¦š")

# Load the question answering model and tokenizer
model_name = "deepset/roberta-base-squad2"
model = AutoModelForQuestionAnswering.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Create a question answering pipeline
nlp = pipeline('question-answering', model=model, tokenizer=tokenizer)

# Get user input
question_input = st.text_input("Question:")
context_input = st.text_area("Context:")

# If the user has entered a question and context, process it
if question_input and context_input:
    QA_input = {
        'question': question_input,
        'context': context_input
    }
    res = nlp(QA_input)
    st.text_area("Answer:", res['answer'])
    st.write("Score:", res['score'])
